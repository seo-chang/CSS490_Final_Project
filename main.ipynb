{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torchvision as vision\n",
    "from torch.utils.data import DataLoader\n",
    "from torchsummary import summary\n",
    "\n",
    "from temp_dataset import TempData"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 16, 16]           9,408\n",
      "       BatchNorm2d-2           [-1, 64, 16, 16]             128\n",
      "              ReLU-3           [-1, 64, 16, 16]               0\n",
      "         MaxPool2d-4             [-1, 64, 8, 8]               0\n",
      "            Conv2d-5            [-1, 128, 8, 8]           8,192\n",
      "       BatchNorm2d-6            [-1, 128, 8, 8]             256\n",
      "              ReLU-7            [-1, 128, 8, 8]               0\n",
      "            Conv2d-8            [-1, 128, 8, 8]         147,456\n",
      "       BatchNorm2d-9            [-1, 128, 8, 8]             256\n",
      "             ReLU-10            [-1, 128, 8, 8]               0\n",
      "           Conv2d-11            [-1, 256, 8, 8]          32,768\n",
      "      BatchNorm2d-12            [-1, 256, 8, 8]             512\n",
      "           Conv2d-13            [-1, 256, 8, 8]          16,384\n",
      "      BatchNorm2d-14            [-1, 256, 8, 8]             512\n",
      "             ReLU-15            [-1, 256, 8, 8]               0\n",
      "       Bottleneck-16            [-1, 256, 8, 8]               0\n",
      "           Conv2d-17            [-1, 128, 8, 8]          32,768\n",
      "      BatchNorm2d-18            [-1, 128, 8, 8]             256\n",
      "             ReLU-19            [-1, 128, 8, 8]               0\n",
      "           Conv2d-20            [-1, 128, 8, 8]         147,456\n",
      "      BatchNorm2d-21            [-1, 128, 8, 8]             256\n",
      "             ReLU-22            [-1, 128, 8, 8]               0\n",
      "           Conv2d-23            [-1, 256, 8, 8]          32,768\n",
      "      BatchNorm2d-24            [-1, 256, 8, 8]             512\n",
      "             ReLU-25            [-1, 256, 8, 8]               0\n",
      "       Bottleneck-26            [-1, 256, 8, 8]               0\n",
      "           Conv2d-27            [-1, 128, 8, 8]          32,768\n",
      "      BatchNorm2d-28            [-1, 128, 8, 8]             256\n",
      "             ReLU-29            [-1, 128, 8, 8]               0\n",
      "           Conv2d-30            [-1, 128, 8, 8]         147,456\n",
      "      BatchNorm2d-31            [-1, 128, 8, 8]             256\n",
      "             ReLU-32            [-1, 128, 8, 8]               0\n",
      "           Conv2d-33            [-1, 256, 8, 8]          32,768\n",
      "      BatchNorm2d-34            [-1, 256, 8, 8]             512\n",
      "             ReLU-35            [-1, 256, 8, 8]               0\n",
      "       Bottleneck-36            [-1, 256, 8, 8]               0\n",
      "           Conv2d-37            [-1, 256, 8, 8]          65,536\n",
      "      BatchNorm2d-38            [-1, 256, 8, 8]             512\n",
      "             ReLU-39            [-1, 256, 8, 8]               0\n",
      "           Conv2d-40            [-1, 256, 4, 4]         589,824\n",
      "      BatchNorm2d-41            [-1, 256, 4, 4]             512\n",
      "             ReLU-42            [-1, 256, 4, 4]               0\n",
      "           Conv2d-43            [-1, 512, 4, 4]         131,072\n",
      "      BatchNorm2d-44            [-1, 512, 4, 4]           1,024\n",
      "           Conv2d-45            [-1, 512, 4, 4]         131,072\n",
      "      BatchNorm2d-46            [-1, 512, 4, 4]           1,024\n",
      "             ReLU-47            [-1, 512, 4, 4]               0\n",
      "       Bottleneck-48            [-1, 512, 4, 4]               0\n",
      "           Conv2d-49            [-1, 256, 4, 4]         131,072\n",
      "      BatchNorm2d-50            [-1, 256, 4, 4]             512\n",
      "             ReLU-51            [-1, 256, 4, 4]               0\n",
      "           Conv2d-52            [-1, 256, 4, 4]         589,824\n",
      "      BatchNorm2d-53            [-1, 256, 4, 4]             512\n",
      "             ReLU-54            [-1, 256, 4, 4]               0\n",
      "           Conv2d-55            [-1, 512, 4, 4]         131,072\n",
      "      BatchNorm2d-56            [-1, 512, 4, 4]           1,024\n",
      "             ReLU-57            [-1, 512, 4, 4]               0\n",
      "       Bottleneck-58            [-1, 512, 4, 4]               0\n",
      "           Conv2d-59            [-1, 256, 4, 4]         131,072\n",
      "      BatchNorm2d-60            [-1, 256, 4, 4]             512\n",
      "             ReLU-61            [-1, 256, 4, 4]               0\n",
      "           Conv2d-62            [-1, 256, 4, 4]         589,824\n",
      "      BatchNorm2d-63            [-1, 256, 4, 4]             512\n",
      "             ReLU-64            [-1, 256, 4, 4]               0\n",
      "           Conv2d-65            [-1, 512, 4, 4]         131,072\n",
      "      BatchNorm2d-66            [-1, 512, 4, 4]           1,024\n",
      "             ReLU-67            [-1, 512, 4, 4]               0\n",
      "       Bottleneck-68            [-1, 512, 4, 4]               0\n",
      "           Conv2d-69            [-1, 256, 4, 4]         131,072\n",
      "      BatchNorm2d-70            [-1, 256, 4, 4]             512\n",
      "             ReLU-71            [-1, 256, 4, 4]               0\n",
      "           Conv2d-72            [-1, 256, 4, 4]         589,824\n",
      "      BatchNorm2d-73            [-1, 256, 4, 4]             512\n",
      "             ReLU-74            [-1, 256, 4, 4]               0\n",
      "           Conv2d-75            [-1, 512, 4, 4]         131,072\n",
      "      BatchNorm2d-76            [-1, 512, 4, 4]           1,024\n",
      "             ReLU-77            [-1, 512, 4, 4]               0\n",
      "       Bottleneck-78            [-1, 512, 4, 4]               0\n",
      "           Conv2d-79            [-1, 512, 4, 4]         262,144\n",
      "      BatchNorm2d-80            [-1, 512, 4, 4]           1,024\n",
      "             ReLU-81            [-1, 512, 4, 4]               0\n",
      "           Conv2d-82            [-1, 512, 2, 2]       2,359,296\n",
      "      BatchNorm2d-83            [-1, 512, 2, 2]           1,024\n",
      "             ReLU-84            [-1, 512, 2, 2]               0\n",
      "           Conv2d-85           [-1, 1024, 2, 2]         524,288\n",
      "      BatchNorm2d-86           [-1, 1024, 2, 2]           2,048\n",
      "           Conv2d-87           [-1, 1024, 2, 2]         524,288\n",
      "      BatchNorm2d-88           [-1, 1024, 2, 2]           2,048\n",
      "             ReLU-89           [-1, 1024, 2, 2]               0\n",
      "       Bottleneck-90           [-1, 1024, 2, 2]               0\n",
      "           Conv2d-91            [-1, 512, 2, 2]         524,288\n",
      "      BatchNorm2d-92            [-1, 512, 2, 2]           1,024\n",
      "             ReLU-93            [-1, 512, 2, 2]               0\n",
      "           Conv2d-94            [-1, 512, 2, 2]       2,359,296\n",
      "      BatchNorm2d-95            [-1, 512, 2, 2]           1,024\n",
      "             ReLU-96            [-1, 512, 2, 2]               0\n",
      "           Conv2d-97           [-1, 1024, 2, 2]         524,288\n",
      "      BatchNorm2d-98           [-1, 1024, 2, 2]           2,048\n",
      "             ReLU-99           [-1, 1024, 2, 2]               0\n",
      "      Bottleneck-100           [-1, 1024, 2, 2]               0\n",
      "          Conv2d-101            [-1, 512, 2, 2]         524,288\n",
      "     BatchNorm2d-102            [-1, 512, 2, 2]           1,024\n",
      "            ReLU-103            [-1, 512, 2, 2]               0\n",
      "          Conv2d-104            [-1, 512, 2, 2]       2,359,296\n",
      "     BatchNorm2d-105            [-1, 512, 2, 2]           1,024\n",
      "            ReLU-106            [-1, 512, 2, 2]               0\n",
      "          Conv2d-107           [-1, 1024, 2, 2]         524,288\n",
      "     BatchNorm2d-108           [-1, 1024, 2, 2]           2,048\n",
      "            ReLU-109           [-1, 1024, 2, 2]               0\n",
      "      Bottleneck-110           [-1, 1024, 2, 2]               0\n",
      "          Conv2d-111            [-1, 512, 2, 2]         524,288\n",
      "     BatchNorm2d-112            [-1, 512, 2, 2]           1,024\n",
      "            ReLU-113            [-1, 512, 2, 2]               0\n",
      "          Conv2d-114            [-1, 512, 2, 2]       2,359,296\n",
      "     BatchNorm2d-115            [-1, 512, 2, 2]           1,024\n",
      "            ReLU-116            [-1, 512, 2, 2]               0\n",
      "          Conv2d-117           [-1, 1024, 2, 2]         524,288\n",
      "     BatchNorm2d-118           [-1, 1024, 2, 2]           2,048\n",
      "            ReLU-119           [-1, 1024, 2, 2]               0\n",
      "      Bottleneck-120           [-1, 1024, 2, 2]               0\n",
      "          Conv2d-121            [-1, 512, 2, 2]         524,288\n",
      "     BatchNorm2d-122            [-1, 512, 2, 2]           1,024\n",
      "            ReLU-123            [-1, 512, 2, 2]               0\n",
      "          Conv2d-124            [-1, 512, 2, 2]       2,359,296\n",
      "     BatchNorm2d-125            [-1, 512, 2, 2]           1,024\n",
      "            ReLU-126            [-1, 512, 2, 2]               0\n",
      "          Conv2d-127           [-1, 1024, 2, 2]         524,288\n",
      "     BatchNorm2d-128           [-1, 1024, 2, 2]           2,048\n",
      "            ReLU-129           [-1, 1024, 2, 2]               0\n",
      "      Bottleneck-130           [-1, 1024, 2, 2]               0\n",
      "          Conv2d-131            [-1, 512, 2, 2]         524,288\n",
      "     BatchNorm2d-132            [-1, 512, 2, 2]           1,024\n",
      "            ReLU-133            [-1, 512, 2, 2]               0\n",
      "          Conv2d-134            [-1, 512, 2, 2]       2,359,296\n",
      "     BatchNorm2d-135            [-1, 512, 2, 2]           1,024\n",
      "            ReLU-136            [-1, 512, 2, 2]               0\n",
      "          Conv2d-137           [-1, 1024, 2, 2]         524,288\n",
      "     BatchNorm2d-138           [-1, 1024, 2, 2]           2,048\n",
      "            ReLU-139           [-1, 1024, 2, 2]               0\n",
      "      Bottleneck-140           [-1, 1024, 2, 2]               0\n",
      "          Conv2d-141           [-1, 1024, 2, 2]       1,048,576\n",
      "     BatchNorm2d-142           [-1, 1024, 2, 2]           2,048\n",
      "            ReLU-143           [-1, 1024, 2, 2]               0\n",
      "          Conv2d-144           [-1, 1024, 1, 1]       9,437,184\n",
      "     BatchNorm2d-145           [-1, 1024, 1, 1]           2,048\n",
      "            ReLU-146           [-1, 1024, 1, 1]               0\n",
      "          Conv2d-147           [-1, 2048, 1, 1]       2,097,152\n",
      "     BatchNorm2d-148           [-1, 2048, 1, 1]           4,096\n",
      "          Conv2d-149           [-1, 2048, 1, 1]       2,097,152\n",
      "     BatchNorm2d-150           [-1, 2048, 1, 1]           4,096\n",
      "            ReLU-151           [-1, 2048, 1, 1]               0\n",
      "      Bottleneck-152           [-1, 2048, 1, 1]               0\n",
      "          Conv2d-153           [-1, 1024, 1, 1]       2,097,152\n",
      "     BatchNorm2d-154           [-1, 1024, 1, 1]           2,048\n",
      "            ReLU-155           [-1, 1024, 1, 1]               0\n",
      "          Conv2d-156           [-1, 1024, 1, 1]       9,437,184\n",
      "     BatchNorm2d-157           [-1, 1024, 1, 1]           2,048\n",
      "            ReLU-158           [-1, 1024, 1, 1]               0\n",
      "          Conv2d-159           [-1, 2048, 1, 1]       2,097,152\n",
      "     BatchNorm2d-160           [-1, 2048, 1, 1]           4,096\n",
      "            ReLU-161           [-1, 2048, 1, 1]               0\n",
      "      Bottleneck-162           [-1, 2048, 1, 1]               0\n",
      "          Conv2d-163           [-1, 1024, 1, 1]       2,097,152\n",
      "     BatchNorm2d-164           [-1, 1024, 1, 1]           2,048\n",
      "            ReLU-165           [-1, 1024, 1, 1]               0\n",
      "          Conv2d-166           [-1, 1024, 1, 1]       9,437,184\n",
      "     BatchNorm2d-167           [-1, 1024, 1, 1]           2,048\n",
      "            ReLU-168           [-1, 1024, 1, 1]               0\n",
      "          Conv2d-169           [-1, 2048, 1, 1]       2,097,152\n",
      "     BatchNorm2d-170           [-1, 2048, 1, 1]           4,096\n",
      "            ReLU-171           [-1, 2048, 1, 1]               0\n",
      "      Bottleneck-172           [-1, 2048, 1, 1]               0\n",
      "AdaptiveAvgPool2d-173           [-1, 2048, 1, 1]               0\n",
      "          Linear-174                 [-1, 1000]       2,049,000\n",
      "================================================================\n",
      "Total params: 68,883,240\n",
      "Trainable params: 68,883,240\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 7.41\n",
      "Params size (MB): 262.77\n",
      "Estimated Total Size (MB): 270.19\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Use pretrained model for comparison\n",
    "model = vision.models.wide_resnet50_2(pretrained=True)\n",
    "\n",
    "summary(model, (3, 32, 32), device=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "616\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "dataset = TempData(file_n=\"/home/jaeha/Storage/Datasets/UTKFace/UTKFace/1_0_0_20161219140627985.jpg.chip.jpg\")\n",
    "dataloader = DataLoader(dataset=dataset, batch_size=1)\n",
    "\n",
    "for batch in dataloader:\n",
    "    res = model(batch)\n",
    "    arr = res.detach().numpy()\n",
    "    print(np.argmax(arr))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}